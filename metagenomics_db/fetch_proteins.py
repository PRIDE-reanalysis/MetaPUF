#-*- coding: utf-8 -*-

# Copyright 2022 EMBL - European Bioinformatics Institute
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import os
import sys
from os import stat

import pandas as pd
from Bio import SeqIO

from metagenomics_db.db_connection import ProteinDatabaseCursor


def get_study_id(study_accession: str):
    """
    sql query to fetch study_id for the given study accession
    :param study_accession: name of the assembled study starting with ERPXXXXXX
    """
    with ProteinDatabaseCursor() as cursor:
        query = (
            "SELECT study.id as study_id FROM emg_peptidedb.study "
            "WHERE study.accession=%(study_accession)s"
        )

        cursor.execute(query, {"study_accession": study_accession})
        # Read a single record
        row = cursor.fetchone()
        if row is None:
            return 0
        return row["study_id"]


def get_proteins(study_accession: str, sample_dict: dict):
    """
    sql query to fetch protein counts from protein_db for all the assemblies
    :param study_accession: study accession
    :param sample_dict:dictionary containing mapping of sample to assembly
    """
    protein_counts = {}
    study = get_study_id(study_accession)

    if study == 0:
        logging.error(f"The study {study_accession} is not in the protein_db")
        sys.exit(1)

    with ProteinDatabaseCursor() as cursor:
        for sample, assemblies in sample_dict.items():

            query = (
                "SELECT count(mgyp_id) as total_mgyp_id FROM emg_peptidedb.protein_metadata "
                "INNER JOIN emg_peptidedb.assembly ON protein_metadata.assembly_id = assembly.id where assembly.accession IN "  # noqa: E501
                "(%(assemblies)s) and assembly.study_id=%(study_id)s;"
            )

            cursor.execute(
                query, {"assemblies": ",'".join(assemblies), "study_id": study}
            )
            rows = cursor.fetchall()
            total_count = 0
            for row in rows:
                total_count += row["total_mgyp_id"]
            protein_counts[sample] = total_count
    return protein_counts


def build_db(cluster_dict, study_acc, database_dir):
    """
    sql query to build protein search database for each cluster of assemlies
    :param cluster_dict: dictionary containing list of assemblies in each cluster
    :param study_accession: study accession of the study generated by ENA
    :param database_dir: Folder containing all the protein search databases
    """
    NUMBER_OF_DIGITS_MGYP = 12
    study_id = get_study_id(study_acc)

    if study_id == 0:
        logging.error(f"The study {study_acc} is not in the protein_db")
        sys.exit(1)

    with ProteinDatabaseCursor() as cursor:
        for group_no, assembly_list in cluster_dict.items():
            cluster_items = []
            data_df = pd.DataFrame(columns=["count", "mgyp_id", "sequence"])
            rec_no = 0
            assembly_id_query = (
                "SELECT assembly.id as assembly_id FROM emg_peptidedb.assembly WHERE assembly.study_id=%s "  # noqa: E501
                f"AND assembly.accession IN ({', '.join(['%s'] * len(assembly_list))})"
            )
            cursor.execute(
                assembly_id_query,
                [study_id] + assembly_list,
            )
            for row in cursor.fetchall():
                cluster_items.append(row["assembly_id"])

            assemblies_ids = map(str, cluster_items)
            db_name = study_acc + "_cluster_set_" + str(group_no) + ".faa"
            database_file = os.path.join(database_dir, db_name)

            for assembly_id in assemblies_ids:
                proteins_query = (
                    "SELECT protein.id as pid, protein.sequence as sequence FROM emg_peptidedb.protein "
                    "RIGHT JOIN emg_peptidedb.protein_metadata ON protein.id=protein_metadata.mgyp_id "
                    "WHERE protein_metadata.assembly_id = %(assembly_id)s LIMIT 500;"
                )
                cursor.execute(proteins_query, {"assembly_id": assembly_id})
                rows = cursor.fetchall()

                for row in rows:
                    data_df.loc[rec_no] = [rec_no, row["pid"], row["sequence"]]
                    rec_no += 1

                with open(database_file, "a", encoding="utf-8") as fout:
                    for i in range(len(data_df)):
                        MGYP = "MGYP" + str(data_df["mgyp_id"][i]).zfill(
                            NUMBER_OF_DIGITS_MGYP
                        )
                        fout.write(">%s\n" % MGYP)
                        fout.write("%s\n" % data_df["sequence"][i])
            total_proteins = (
                "Total number of proteins in the database are "
                + "group_"
                + str(group_no)
                + ": "
                + str(data_df["count"].max() + 1)
            )
            db_size = "The estimated size of database is " + str(
                stat(database_file).st_size
            )
            cluster_report = os.path.join(database_dir, "cluster_report.txt")
            with open(cluster_report, "a", encoding="utf-8") as fin:
                fin.write("\n")
                fin.write(total_proteins + "\n")
                fin.write(db_size + "\n")


def uniq_proteins(d_dir: str, db_name: str):
    """
    generate the protein search database with unique protein sequences
    :param d_dir:  path of directory containing databases
    :param db_name: name of the search database
    """
    unique_records = {}
    protein_file = os.path.join(d_dir, db_name)
    uniq_db = os.path.join(d_dir, "unique_" + db_name)
    for record in SeqIO.parse(protein_file, "fasta"):
        # if str(record.id) not in unique_records.keys():
        if str(record.id) not in unique_records:
            unique_records[str(record.id)] = record.seq
    with open(uniq_db, "w") as fout:
        for k, v in unique_records.items():
            fout.write(">" + k + "\n")
            fout.write(str(v) + "\n")

def remove_file(file_name):
    try:
        os.remove(file_name)
    except OSError as e:  ## if failed, report it back to the user ##
        print ("Error: %s - %s." % (e.filename, e.strerror))
